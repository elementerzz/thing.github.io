<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Mic Monitor — Low-Latency Reverb (Stable)</title>
  <style>
    body{font-family:Inter,system-ui,Arial;background:#071021;color:#e6eef6;padding:22px}
    .card{max-width:980px;margin:0 auto;background:linear-gradient(180deg,rgba(255,255,255,0.02),rgba(255,255,255,0.01));padding:18px;border-radius:12px}
    h1{margin:0 0 6px}
    .controls{display:grid;grid-template-columns:1fr 360px;gap:14px}
    .btn-row{display:flex;gap:8px;margin-bottom:10px}
    button{padding:10px 12px;border-radius:8px;border:0;font-weight:600;cursor:pointer}
    .start{background:#10b981;color:#02140d}.stop{background:#ef4444}
    label{font-size:13px;color:#9aa4b2}
    input[type=range]{width:100%}
    select,input[type=number]{width:100%;padding:8px;border-radius:6px;border:1px solid rgba(255,255,255,0.04);background:transparent;color:inherit}
    .section{background:rgba(255,255,255,0.02);padding:12px;border-radius:10px;margin-bottom:10px}
    .meter{height:44px;border-radius:8px;background:linear-gradient(90deg,#072033,#05121e);display:flex;align-items:center;padding:6px}
    .meter-bar{flex:1;height:24px;border-radius:6px;background:#041829;position:relative;overflow:hidden}
    .meter-fill{position:absolute;left:0;top:0;bottom:0;width:0%;background:linear-gradient(90deg,#10b981,#06b6d4)}
    .log{font-family:monospace;font-size:12px;color:#9fb7c9;max-height:160px;overflow:auto;background:rgba(2,6,10,0.4);padding:8px;border-radius:6px;margin-top:8px}
    .small{font-size:13px;color:#9aa4b2}
    .status{font-weight:700;margin-top:8px}
    .row{display:flex;gap:8px;align-items:center}
  </style>
</head>
<body>
  <div class="card">
    <h1>Mic Monitor — Low-Latency Reverb (Stable)</h1>
    <p class="small">This page now includes a robust low-latency AudioWorklet reverb plus a safe convolution fallback. I added an explicit <strong>Test Reverb</strong> button (plays a short impulse) so you can confirm reverb is working without speaking. Use Aggressive Mode for the worklet reverb (lowest latency). If the worklet fails, the page will automatically build a convolution IR and use it.</p>

    <div class="controls">
      <div>
        <div class="btn-row">
          <button id="startBtn" class="start">Start monitoring</button>
          <button id="stopBtn" class="stop" disabled>Stop</button>
          <button id="muteBtn">Mute</button>
        </div>

        <div class="section">
          <label>Input device</label>
          <select id="inputSelect"></select>
          <label>Monitor gain</label>
          <input id="gain" type="range" min="0" max="2" step="0.01" value="0.8">
        </div>

        <div class="section">
          <label><input type="checkbox" id="aggressiveMode"> Aggressive Low-Latency (Worklet Reverb)</label>
          <div class="small">When enabled, reverb and monitoring run inside an AudioWorklet for minimal buffering. If the worklet cannot be loaded the page will fall back to convolution IR automatically.</div>

          <label style="margin-top:8px"><input type="checkbox" id="directMonitor"> Direct Monitor (bias to dry)</label>
          <div class="small">Keep checked for lowest latency; uncheck to let reverb be more audible.</div>
        </div>

        <div class="section">
          <label>Reverb — Wet (0–1)</label>
          <input id="wet" type="range" min="0" max="1" step="0.01" value="0.45">
          <label>Decay (s)</label>
          <input id="decay" type="range" min="0.2" max="6" step="0.1" value="2.4">
          <label>Pre-delay (ms)</label>
          <input id="preDelay" type="range" min="0" max="120" step="1" value="18">

          <div style="margin-top:8px" class="row">
            <button id="testReverb">Test Reverb</button>
            <button id="forceFallback">Force Convolver (fallback)</button>
          </div>
          <div class="status" id="reverbStatus">Reverb status: unknown</div>
        </div>

      </div>

      <div>
        <div class="section">
          <label>VU Meter</label>
          <div class="meter"><div class="meter-bar"><div id="meterFill" class="meter-fill"></div></div></div>
          <div id="statusText" class="small">Status: stopped</div>
          <div id="eventLog" class="log"></div>
        </div>

        <div class="section">
          <label>Latency tips</label>
          <div class="small"><ul>
            <li>Use Chrome or Firefox (latest).</li>
            <li>Use wired headphones (no Bluetooth) and preferably a USB or built-in mic.</li>
            <li>Enable <strong>Aggressive Low-Latency</strong> for the worklet reverb; if it fails the page will fall back to convolution automatically.</li>
          </ul></div>
        </div>
      </div>
    </div>

    <div class="small" style="margin-top:12px">If it still doesn't show reverb after these tests, open the browser console (Inspect → Console) and paste the last 20 lines here so I can patch the exact failure.</div>
  </div>

<script>
(async function(){
  // UI references
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const muteBtn = document.getElementById('muteBtn');
  const inputSelect = document.getElementById('inputSelect');
  const gainSlider = document.getElementById('gain');
  const meterFill = document.getElementById('meterFill');
  const statusText = document.getElementById('statusText');
  const eventLog = document.getElementById('eventLog');
  const aggressiveCheckbox = document.getElementById('aggressiveMode');
  const directCheckbox = document.getElementById('directMonitor');
  const wetControl = document.getElementById('wet');
  const decayControl = document.getElementById('decay');
  const preDelayControl = document.getElementById('preDelay');
  const testBtn = document.getElementById('testReverb');
  const fallbackBtn = document.getElementById('forceFallback');
  const reverbStatusEl = document.getElementById('reverbStatus');

  function log(msg){ const t=new Date().toLocaleTimeString(); eventLog.textContent = `[${t}] ${msg}
` + eventLog.textContent; console.log('[MicMon]',msg); }
  function setStatus(s){ statusText.textContent = 'Status: '+s; log(s); }
  function setReverbStatus(s){ reverbStatusEl.textContent = 'Reverb status: '+s; log('reverb: '+s); }

  let audioCtx=null, stream=null, srcNode=null;
  let postGain=null, analyser=null;
  let workletNode=null, workletAvailable=false;
  let convolver=null, wetGain=null, dryGain=null, delayNode=null;
  let rafId=null; let muted=false; let forcedFallback=false;

  async function enumerateInputs(){ try{ const devs = await navigator.mediaDevices.enumerateDevices(); const ins = devs.filter(d=>d.kind==='audioinput'); const cur = inputSelect.value; inputSelect.innerHTML=''; ins.forEach(d=>{ const o=document.createElement('option'); o.value=d.deviceId; o.textContent=d.label||('Mic('+d.deviceId.slice(-4)+')'); inputSelect.appendChild(o); }); if (cur) inputSelect.value = cur; }catch(e){ inputSelect.innerHTML=''; const o=document.createElement('option'); o.value=''; o.textContent='Default microphone'; inputSelect.appendChild(o); } }

  function createAudioContext(){ if (audioCtx) return; try{ audioCtx = new (window.AudioContext||window.webkitAudioContext)({ latencyHint:'interactive' }); }catch(e){ audioCtx = new (window.AudioContext||window.webkitAudioContext)(); }
    postGain = audioCtx.createGain(); analyser = audioCtx.createAnalyser(); analyser.fftSize = 256; postGain.connect(analyser); analyser.connect(audioCtx.destination); postGain.gain.value = parseFloat(gainSlider.value);
    // convolver path
    convolver = audioCtx.createConvolver(); wetGain = audioCtx.createGain(); dryGain = audioCtx.createGain(); delayNode = audioCtx.createDelay(2.0);
    // wet/dry routing into postGain
    wetGain.connect(postGain); dryGain.connect(postGain);
    wetGain.gain.value = parseFloat(wetControl.value); dryGain.gain.value = 1 - parseFloat(wetControl.value);
    audioCtx.onstatechange = ()=>{ log('audioCtx: '+audioCtx.state); if (audioCtx.state==='suspended') audioCtx.resume().catch(()=>{}); };
  }

  // Worklet code: compact low-latency reverb (Schroeder + predelay)
  const workletCode = `
  class LLReverb extends AudioWorkletProcessor {
    constructor(){
      super(); this.sampleRate = sampleRate;
      this.preDelayMax = Math.floor(0.12*this.sampleRate);
      this.preBuf = new Float32Array(this.preDelayMax); this.preIdx = 0; this.preSamples = Math.floor(0.018*this.sampleRate);
      // simple comb/allpass network
      this.combLens = [0.0297,0.0371,0.0411,0.0437].map(d=>Math.floor(d*this.sampleRate));
      this.combBufs = this.combLens.map(l=>new Float32Array(l)); this.combIdx = new Array(this.combLens.length).fill(0);
      this.combG = new Array(this.combLens.length).fill(0.78);
      this.apLens = [0.005,0.0017].map(d=>Math.floor(d*this.sampleRate)); this.apBufs = this.apLens.map(l=>new Float32Array(l)); this.apIdx = new Array(this.apLens.length).fill(0);
      this.apG = [0.7,0.5]; this.wet=0.45; this.dry=0.55; this.decay=2.4; this.port.onmessage=(e)=>{ const d=e.data; if(d.wet!==undefined) this.wet=d.wet; if(d.decay!==undefined) this.decay=d.decay; if(d.preDelayMs!==undefined) this.preSamples = Math.min(this.preDelayMax, Math.floor(d.preDelayMs*this.sampleRate/1000)); if(d.dry!==undefined) this.dry=d.dry; } }
    process(inputs,outputs){ const input = inputs[0]; const output = outputs[0]; if(!input||!input[0]||!output||!output[0]) return true; const inBuf = input[0]; const outBuf = output[0]; for(let i=0;i<inBuf.length;i++){ // pre-delay
        this.preBuf[this.preIdx] = inBuf[i]; const readIdx = (this.preIdx - this.preSamples + this.preDelayMax) % this.preDelayMax; const pre = this.preBuf[readIdx]; this.preIdx = (this.preIdx+1)%this.preDelayMax;
        // comb
        let csum=0; for(let c=0;c<this.combBufs.length;c++){ const buf=this.combBufs[c]; const idx=this.combIdx[c]; const out = buf[idx]; buf[idx] = pre + out*this.combG[c]; this.combIdx[c] = (idx+1)%buf.length; csum+=out; }
        // allpass
        let ap=csum; for(let a=0;a<this.apBufs.length;a++){ const buf=this.apBufs[a]; const idx=this.apIdx[a]; const bout = buf[idx]; const inp = ap; buf[idx] = inp + bout*this.apG[a]; ap = bout - inp*this.apG[a]; this.apIdx[a] = (idx+1)%buf.length; }
        const wetSample = ap*0.5; outBuf[i] = inBuf[i]*this.dry + wetSample*this.wet; } return true; }
  }
  registerProcessor('ll-reverb',LLReverb);
  `;

  async function loadWorklet(){ if (!audioCtx) createAudioContext(); if (!audioCtx.audioWorklet) { workletAvailable=false; setReverbStatus('worklet not supported'); return false; }
    if (workletAvailable) return true;
    try{ const blob = new Blob([workletCode], {type:'application/javascript'}); const url = URL.createObjectURL(blob); await audioCtx.audioWorklet.addModule(url); workletNode = new AudioWorkletNode(audioCtx,'ll-reverb'); // initial params
      workletNode.port.postMessage({wet: parseFloat(wetControl.value), decay: parseFloat(decayControl.value), preDelayMs: parseFloat(preDelayControl.value), dry: 1-parseFloat(wetControl.value)});
      workletAvailable = true; setReverbStatus('worklet loaded'); return true; }catch(err){ console.warn('worklet load failed', err); workletAvailable=false; setReverbStatus('worklet failed: '+(err&&err.message)); return false; } }

  // build convolution IR fallback (async, using OfflineAudioContext)
  async function buildConvolverIR(decaySec=2.4,preset='masjid'){ if (!audioCtx) createAudioContext(); setReverbStatus('building IR...'); try{ const capped = Math.min(6,Math.max(0.2,decaySec)); const rate = audioCtx.sampleRate; const len = Math.floor(rate*capped); const offline = new OfflineAudioContext(2,len,rate); const ir = offline.createBuffer(2,len,rate); for(let ch=0;ch<2;ch++){ const data = ir.getChannelData(ch); for(let i=0;i<len;i++){ const t=i/len; const decay = Math.pow(1-t,capped*1.8); const n = (Math.random()*2-1); data[i] = n*decay*(0.9 - 0.6*t); } } const src = offline.createBufferSource(); src.buffer = ir; src.connect(offline.destination); src.start(); const rendered = await offline.startRendering(); convolver.buffer = rendered; setReverbStatus('convolver ready'); return true; }catch(err){ console.warn('IR build failed',err); setReverbStatus('IR build failed'); return false; } }

  function startMetering(){ const buf = new Uint8Array(analyser.frequencyBinCount); function loop(){ analyser.getByteTimeDomainData(buf); let peak=0; for(let i=0;i<buf.length;i++){ const v=Math.abs(buf[i]-128)/128; if(v>peak) peak=v; } meterFill.style.width = (Math.min(1,peak)*100)+'%'; rafId=requestAnimationFrame(loop); } rafId=requestAnimationFrame(loop); }

  async function startStream(){ try{ setStatus('requesting microphone'); const constraints = { audio: { deviceId: inputSelect.value||undefined, echoCancellation:false, noiseSuppression:false, autoGainControl:false, channelCount:1, latency:{ideal:0} } }; stream = await navigator.mediaDevices.getUserMedia(constraints); const t = stream.getTracks()[0]; if (t){ t.onended = ()=>{ log('track ended'); setStatus('track ended'); }; t.onmute = ()=>{ log('track muted'); setStatus('track muted'); } }
      if (srcNode) try{ srcNode.disconnect(); }catch(e){}
      srcNode = audioCtx.createMediaStreamSource(stream);

      // disconnect any previous worklet/convolver
      try{ if (workletNode) workletNode.disconnect(); }catch(e){}
      try{ if (convolver) convolver.disconnect(); }catch(e){}

      // routing choice
      if (aggressiveCheckbox.checked && !forcedFallback){ const ok = await loadWorklet(); if (ok && workletNode){ // route src -> worklet -> postGain
            try{ srcNode.connect(workletNode); workletNode.connect(postGain); setReverbStatus('worklet active'); log('using worklet'); }
            catch(e){ log('worklet connect failed, falling back'); forcedFallback=true; await ensureConvolverAndRoute(); }
        } else { await ensureConvolverAndRoute(); }
      } else { await ensureConvolverAndRoute(); }

      postGain.gain.setValueAtTime(parseFloat(gainSlider.value), audioCtx.currentTime);
      startMetering(); setStatus('monitoring — live');
  }catch(err){ console.error(err); setStatus('mic unavailable'); log('getUserMedia error: '+(err&&err.message)); } }

  async function ensureConvolverAndRoute(){ // build IR if not present
    if (!convolver.buffer){ await buildConvolverIR(parseFloat(decayControl.value)); }
    // route: src -> dryGain -> postGain ; src -> delay -> convolver -> wetGain -> postGain
    try{ srcNode.connect(dryGain); srcNode.connect(delayNode); delayNode.connect(convolver); convolver.connect(wetGain); setReverbStatus('convolver active'); log('using convolver fallback'); }catch(e){ console.warn('convolver routing failed',e); }
  }

  // Test reverb by emitting a short impulse (via BufferSource) through the same route
  function playImpulse(){ if (!audioCtx) createAudioContext(); const buf = audioCtx.createBuffer(1, audioCtx.sampleRate*1, audioCtx.sampleRate); const data = buf.getChannelData(0); // short impulse at start
    data[0] = 1.0; for(let i=1;i<buf.length;i++) data[i]=0; const src = audioCtx.createBufferSource(); src.buffer = buf; // route through same routing: we'll connect to either worklet node or to convolver/dry
    if (aggressiveCheckbox.checked && workletAvailable && !forcedFallback){ try{ const merger = audioCtx.createGain(); const tmpNode = audioCtx.createBufferSource(); tmpNode.buffer = buf; // use audio graph: buffer -> worklet -> postGain
          tmpNode.connect(workletNode); workletNode.connect(postGain); tmpNode.start(); log('played impulse (worklet)'); setTimeout(()=>{ try{ tmpNode.disconnect(); }catch(e){} }, 1200); return; }catch(e){ log('impulse worklet failed, falling back'); forcedFallback=true; }
    }
    // fallback path: buffer -> delay -> convolver -> wetGain -> postGain, plus dry
    const tmp = audioCtx.createBufferSource(); tmp.buffer = buf;
    tmp.connect(dryGain); tmp.connect(delayNode); tmp.start(); log('played impulse (convolver)'); setTimeout(()=>{ try{ tmp.disconnect(); }catch(e){} }, 1200);
  }

  // UI handlers
  startBtn.addEventListener('click', async ()=>{ startBtn.disabled=true; try{ await enumerateInputs(); createAudioContext(); if (audioCtx.state==='suspended') await audioCtx.resume(); await startStream(); stopBtn.disabled=false; }catch(e){ console.error(e); startBtn.disabled=false; setStatus('error starting'); } });
  stopBtn.addEventListener('click', ()=>{ if (rafId) cancelAnimationFrame(rafId); try{ if (srcNode) srcNode.disconnect(); }catch(e){} try{ if (stream) stream.getTracks().forEach(t=>t.stop()); }catch(e){} stream=null; srcNode=null; setStatus('stopped'); startBtn.disabled=false; stopBtn.disabled=true; });
  muteBtn.addEventListener('click', ()=>{ muted=!muted; if (muted && postGain) postGain.gain.setValueAtTime(0.0001,audioCtx.currentTime); else if (postGain) postGain.gain.setValueAtTime(parseFloat(gainSlider.value),audioCtx.currentTime); });
  gainSlider.addEventListener('input', ()=>{ if (postGain) postGain.gain.value=parseFloat(gainSlider.value); if (workletNode) workletNode.port.postMessage({gain:parseFloat(gainSlider.value)}); });
  wetControl.addEventListener('input', ()=>{ if (wetGain) wetGain.gain.value=parseFloat(wetControl.value); if (dryGain) dryGain.gain.value = 1 - parseFloat(wetControl.value); if (workletNode) workletNode.port.postMessage({wet:parseFloat(wetControl.value), dry:1-parseFloat(wetControl.value)}); });
  decayControl.addEventListener('input', ()=>{ if (workletNode) workletNode.port.postMessage({decay:parseFloat(decayControl.value)}); });
  preDelayControl.addEventListener('input', ()=>{ if (workletNode) workletNode.port.postMessage({preDelayMs:parseFloat(preDelayControl.value)}); if (delayNode) delayNode.delayTime.value = parseFloat(preDelayControl.value)/1000; });
  testBtn.addEventListener('click', ()=>{ if (!audioCtx) createAudioContext(); playImpulse(); });
  fallbackBtn.addEventListener('click', async ()=>{ forcedFallback=true; if (stream){ try{ if (srcNode) srcNode.disconnect(); }catch(e){} await ensureConvolverAndRoute(); setStatus('forced convolver fallback'); } });

  navigator.mediaDevices && navigator.mediaDevices.addEventListener && navigator.mediaDevices.addEventListener('devicechange', async ()=>{ log('devicechange'); await enumerateInputs(); });
  enumerateInputs();

})();
</script>
</body>
</html>
